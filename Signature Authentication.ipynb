{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d9d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a19a5f0",
   "metadata": {},
   "source": [
    "Importing Libraries :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd45d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf0d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = 'D:/Project/Signature Authentication/sign dataset/dataset/fraud dataset'\n",
    "forge_path = 'D:/Project/Signature Authentication/sign dataset/dataset/orininal dataset'\n",
    "\n",
    "real_images = []\n",
    "for img_name in os.listdir(real_path):\n",
    "    img = cv2.imread(os.path.join(real_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "    real_images.append(img)\n",
    "real_images = np.array(real_images, dtype=object)\n",
    "\n",
    "forge_images = []\n",
    "for img_name in os.listdir(forge_path):\n",
    "    img = cv2.imread(os.path.join(forge_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "    forge_images.append(img)\n",
    "forge_images = np.array(forge_images, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99576141",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = np.zeros(real_images.shape[0])\n",
    "forge_labels = np.ones(forge_images.shape[0])\n",
    "\n",
    "X = np.concatenate((real_images, forge_images), axis=0)\n",
    "y = np.concatenate((real_labels, forge_labels), axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835dca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load the dataset\n",
    "real_path = 'D:/Project/Signature Authentication/sign dataset/dataset/fraud dataset'\n",
    "forge_path = 'D:/Project/Signature Authentication/sign dataset/dataset/orininal dataset'\n",
    "\n",
    "# set the image size to 128x128\n",
    "img_size = (128, 128)\n",
    "\n",
    "real_images = []\n",
    "for img_name in os.listdir(real_path):\n",
    "    img = cv2.imread(os.path.join(real_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    real_images.append(img)\n",
    "real_images = np.array(real_images)\n",
    "\n",
    "forge_images = []\n",
    "for img_name in os.listdir(forge_path):\n",
    "    img = cv2.imread(os.path.join(forge_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    forge_images.append(img)\n",
    "forge_images = np.array(forge_images)\n",
    "\n",
    "# normalize the data\n",
    "real_images = real_images.astype('float32') / 255.0\n",
    "forge_images = forge_images.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6db0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_real_images = len(real_images)\n",
    "num_forge_images = len(forge_images)\n",
    "\n",
    "# Create labels for the real and forged signatures\n",
    "real_labels = np.zeros(num_real_images, dtype=int)\n",
    "forge_labels = np.ones(num_forge_images, dtype=int)\n",
    "\n",
    "# Concatenate the real and forged images and labels\n",
    "X = np.concatenate((real_images, forge_images), axis=0)\n",
    "y = np.concatenate((real_labels, forge_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60845f5-05b2-4ac2-bd3d-3e431eb5db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create dummy data\n",
    "X_train = np.random.rand(40, 128, 128)\n",
    "\n",
    "# add another dimension to the array\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "\n",
    "# reshape the array\n",
    "X_train = X_train.reshape(X_train.shape[0], 128, 128, 1)\n",
    "\n",
    "print(X_train.shape)  # output: (40, 128, 128, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7a6115-7f56-493c-9e28-c36a649ca706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create dummy data\n",
    "X_test = np.random.rand(40, 128, 128)\n",
    "\n",
    "# add another dimension to the array\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# reshape the array\n",
    "X_test = X_train.reshape(X_test.shape[0], 128, 128, 1)\n",
    "\n",
    "print(X_train.shape)  # output: (40, 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71880334-6594-4918-a31a-584a3ee8548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               7372928   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7391873 (28.20 MB)\n",
      "Trainable params: 7391873 (28.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(128, 128, 1)))\n",
    "\n",
    "# Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "# Add another max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Flatten the output from the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer with 128 neurons and a relu activation function\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Add a dropout layer to reduce overfitting\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "# Add the output layer with a sigmoid activation function\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Print a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b6ec5-7d67-487f-b32b-e514d8343bd0",
   "metadata": {},
   "source": [
    "EVALUATING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3915a1f-a786-4419-84d3-af31279bde1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 763ms/step - loss: 1.8153 - accuracy: 0.3750 - val_loss: 2.8875 - val_accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.7862 - accuracy: 0.5000 - val_loss: 0.6111 - val_accuracy: 0.7000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.8321 - accuracy: 0.4000 - val_loss: 0.6497 - val_accuracy: 0.7000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.6881 - accuracy: 0.6000 - val_loss: 0.7260 - val_accuracy: 0.3000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.6709 - accuracy: 0.6000 - val_loss: 0.7709 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 333ms/step - loss: 0.6892 - accuracy: 0.5750 - val_loss: 0.7646 - val_accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.6827 - accuracy: 0.5500 - val_loss: 0.7363 - val_accuracy: 0.3000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.6794 - accuracy: 0.5500 - val_loss: 0.7349 - val_accuracy: 0.3000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 267ms/step - loss: 0.6519 - accuracy: 0.6000 - val_loss: 0.7989 - val_accuracy: 0.3000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 253ms/step - loss: 0.6582 - accuracy: 0.6000 - val_loss: 0.7157 - val_accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6a8da-cfb9-4ed1-8113-dde73634438c",
   "metadata": {},
   "source": [
    "TESTING LOAD AND ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c1254e-5bd1-4f44-8f9d-fb6552d65789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7157 - accuracy: 0.3000\n",
      "Test accuracy: 0.30000001192092896\n",
      "Test loss: 0.7156566381454468\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4810091d-f9c9-4da9-8715-d219f65e7dfb",
   "metadata": {},
   "source": [
    "DETECTION OF REAL AND FORGED SIGNATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fffe2600-17e4-41fb-b84c-0ba05fdf6c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n",
      "The signature is real.\n"
     ]
    }
   ],
   "source": [
    "# Load a signature image\n",
    "# You can change the image path and check if it is forged or real\n",
    "img = cv2.imread('D:/Project/Signature Authentication/sign dataset/dataset/orininal dataset/agh2_1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (128, 128))\n",
    "img = np.array(img).reshape(1, 128, 128, 1) / 255.0\n",
    "\n",
    "# Predict the class of the signature image\n",
    "prediction = model.predict(img)\n",
    "\n",
    "if prediction < 0.5:\n",
    "    print(\"The signature is real.\")\n",
    "else:\n",
    "    print(\"The signature is forged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b79ed1f-eacc-4e87-9625-e365c6439f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15552\\939735350.py:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model,'my_model2.hdf5')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model,'my_model2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c97bbb8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.28.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.1.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.8.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.24.3)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.1.1)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (10.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.24.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (14.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (13.7.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.5.0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.1.40)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b6f8277-4f69-422e-a911-9a7f48fac804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL\n",
    "import os\n",
    "# from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fba6acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "st.set_option('deprication.showfileUploadingEncoding',False)\n",
    "@st.cache(allow_output_mutation = True)\n",
    "def load_model1():\n",
    "    model =tf.keras.models.load_model('Signature Authentication/my_model2.hdf5')\n",
    "    return model\n",
    "model = load_model()\n",
    "st.write(\"\"\"\n",
    "            #Signature Authentication\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "file = sr.file_uploader(\"Please upload an signature image\" , type = [\"jpg\",\"png\"])\n",
    "import cv2\n",
    "from PIL import Image,Image Ops\n",
    "import numpy as np\n",
    "def import_and_predict(image_data,model):\n",
    "    size = (128,128)\n",
    "    image = ImageOps.fit(image_data,Image.ANTIALIAS)\n",
    "    img = np.asarray(image)\n",
    "    img_reshape = img[np.newaxis,...]\n",
    "    prediction = model.predit(img_reshape)\n",
    "    return prediction\n",
    "\n",
    "if file is None:\n",
    "    st.text(\"Please upload an image file\")\n",
    "else :\n",
    "    image = Image.open(file)\n",
    "    st.image(image,use_column_width =True)\n",
    "    predictions = import_and_predict(image,model)\n",
    "    if predictions < 0.5:\n",
    "        string = \"The signature is real.\"\n",
    "    else:\n",
    "        string = \"The signature is forged.\"\n",
    "    st.success(string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff7a117d-5997-408d-9d47-d6ff232a71bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyngrok in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (7.0.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyngrok) (6.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "639f5006-e99a-4055-8a15-bfe937db1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrok config add-authtoken 2YiZd8Mld03EBi58b4e0vhMBVtq_EnSonQAsL6saNCr1xQFb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71c7d588-170d-492f-bc68-115521977d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ngrok ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1348, in do_open\n",
      "    h.request(req.get_method(), req.selector, req.data, headers,\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1286, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1332, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1281, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1041, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 979, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py\", line 1458, in connect\n",
      "    self.sock = self._context.wrap_socket(self.sock,\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 1075, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py\", line 1346, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1002)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\installer.py\", line 117, in install_ngrok\n",
      "    download_path = _download_file(url, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\installer.py\", line 252, in _download_file\n",
      "    response = urlopen(url, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 519, in open\n",
      "    response = self._open(req, data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 536, in _open\n",
      "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 496, in _call_chain\n",
      "    result = func(*args)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1391, in https_open\n",
      "    return self.do_open(http.client.HTTPSConnection, req,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py\", line 1351, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1002)>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\ngrok.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\ngrok.py\", line 567, in main\n",
      "    run(sys.argv[1:])\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\ngrok.py\", line 553, in run\n",
      "    install_ngrok(pyngrok_config)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\ngrok.py\", line 96, in install_ngrok\n",
      "    installer.install_ngrok(pyngrok_config.ngrok_path, ngrok_version=pyngrok_config.ngrok_version)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\installer.py\", line 121, in install_ngrok\n",
      "    raise PyngrokNgrokInstallError(\"An error occurred while downloading ngrok from {}: {}\".format(url, e))\n",
      "pyngrok.exception.PyngrokNgrokInstallError: An error occurred while downloading ngrok from https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-windows-amd64.zip: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1002)>\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken 2YiZd8Mld03EBi58b4e0vhMBVtq_EnSonQAsL6saNCr1xQFb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5561f3a-9c91-4540-bf6e-8392690394dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at /Signature Authentication/my_model2.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m modelxx \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Signature Authentication/my_model2.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    231\u001b[0m         filepath,\n\u001b[0;32m    232\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    234\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         )\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    241\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at /Signature Authentication/my_model2.hdf5"
     ]
    }
   ],
   "source": [
    "modelxx = tf.keras.models.load_model('/Signature Authentication/my_model2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac22a56-dbc9-4c18-8ff5-9a07c7cae675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
